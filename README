Air Quality Data Pipeline

Overview
This project automates the retrieval, cleaning, and visualization of daily air quality data (PM2.5 and O₃) for the state of Maine using the OpenAQ API. It includes two implementations:
A Python-based pipeline for scripted execution and Cron scheduling.
An n8n workflow that reproduces the same functionality using a node-based automation platform.
The system ingests sensor data, validates and deduplicates records, stores clean CSV files, and generates an interactive Plotly visualization of the most recent three weeks of measurements.

Setup

Python Environment
Install Python 3.13 or newer.

Create and activate a virtual environment:
python -m venv .venv
source .venv/bin/activate # or .venv\Scripts\activate on Windows

Install dependencies:
pip install -r requirements.txt

Create a .env file containing your OpenAQ API key:
OPENAQ_API_KEY=your_key_here

n8n Environment
Run n8n (cloud). This workflow was developed and tested with n8n v1.117.3.

Import the exported workflow file from:
workflows/OpenAQ_AirQuality_Workflow.json

Configure your OpenAQ API key using n8n’s Credentials Manager (stored securely — no secrets in the repo).

Optional: enable Cron Trigger to match the Python job schedule (daily at 11:00 UTC).

Files and Folders
data/raw/ → Raw JSONL files from API
data/clean/ → Cleaned CSV outputs
data/fetch.log → Log file per run
viz/viz.py → Visualization generator (Plotly)
viz/chart.html → Interactive visualization
RunPipeline.sh → Cron wrapper script
requirements.txt → Python dependencies
workflows/ → Exported n8n workflow JSON
.env.example → API key template

What It Does

Python Job
Fetches daily OpenAQ sensor data for Maine.
Cleans and validates PM2.5 and O₃ data.
Removes duplicates based on sensor_id + datetime_from.
Saves results to:
data/clean/cleaned_data_YYYY-MM-DD.csv
data/clean/data_store.csv (aggregated)
Generates an HTML Plotly chart (viz/chart.html) showing daily averages per sensor.

n8n Workflow
Recreates the same stages using n8n nodes:
Python Stage → n8n Node(s)
Cron / Trigger → Manual Trigger → Cron
Fetch Locations → HTTP Request (GET /locations)
Extract Sensors → Code (JavaScript)
Fetch Measurements → Split In Batches → HTTP Request (GET /sensors/{id}/days)
Pagination → IF → Set → Wait (loop)
Validation → Function (filter missing/invalid)
Dedupe → Code (filter unique sensor_id + datetime_from)
Persistence → Move Binary Data → Write Binary File
Visualization → Optional external step calling viz.py
Error Handling → Error Trigger (logs to file)

Scheduling (CRON)
The OpenAQ API updates daily around midnight EST.
The Python pipeline runs once daily at 11:00 UTC (6:00 AM EST).

Cron line example:
0 11 * * * /absolute/path/to/project/RunPipeline.sh >> /absolute/path/to/project/data/raw/fetch_$(date +%F).log 2>&1

n8n Cron node:
Equivalent schedule configured as:
Every day at 11:00 UTC

Runbook

**DONT FORGET TO PUT YOUR STUFF HERE**

Visualization
The visualization displays daily averages of PM2.5 and O₃ per sensor across the past three weeks.

Chart Interpretation
Each colored line = one sensor location in Maine.
Hover tooltips show sensor name and measurement values.
Useful for identifying air quality trends and anomalies.

To regenerate manually:
python viz/viz.py

Outputs to:
viz/chart.html

n8n Workflow Overview

Flow Diagram:

Outputs

data/clean/cleaned_data_YYYY-MM-DD.csv

data/clean/data_store.csv

Optional outputs/summary_PM25.csv or summary_O3.csv

Troubleshooting

404 / empty pages → verify sensor_id and date range logic.
429 rate limits → increase Wait node delay to 300–500ms.
No chart output → confirm data_store.csv exists and contains recent data.

Security

No API keys or tokens in code or repo.

.env and data directories excluded via .gitignore.

n8n credentials are not stored. credentials manager errors.

Version & License
Python: 3.13
n8n: 1.117.3 (Cloud)
API: OpenAQ v3
License: MIT
